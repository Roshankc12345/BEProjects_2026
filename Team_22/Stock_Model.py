# -*- coding: utf-8 -*-
"""team22.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TuM65lpvnK8dCHCjTFGLJZBgFkp2WCpk
"""

# --- SETUP ---
!pip install yfinance pandas numpy scikit-learn transformers matplotlib --quiet

import yfinance as yf
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from transformers import pipeline
import matplotlib.pyplot as plt

#--- PARAMETERS AND STOCK DATA ---
stock_symbol = 'RELIANCE.NS'
start_date = '2022-01-01'
end_date = '2024-01-01'

df_price = yf.download(stock_symbol, start=start_date, end=end_date)
df_price['ReturnPct'] = df_price['Close'].pct_change()*100
df_price['MA_5'] = df_price['Close'].rolling(5).mean()
df_price['MA_21'] = df_price['Close'].rolling(21).mean()
df_price['Volatility_10'] = df_price['ReturnPct'].rolling(10).std()

#--- SIMULATED RECENT HEADLINES ---
news_data = [
    {"date": "2023-02-05", "headline": "Reliance posts strong profits, retail surges"},
    {"date": "2023-03-12", "headline": "Oil price drop impacts Reliance refining margins"},
    {"date": "2023-05-28", "headline": "RBI keeps rates steady, market remains bullish"},
    {"date": "2023-07-09", "headline": "Reliance faces telecom regulatory challenges"},
    {"date": "2023-08-15", "headline": "Reliance launches new retail segment"},
    {"date": "2023-09-14", "headline": "Monsoon boosts Reliance agriculture business"},
    {"date": "2023-10-22", "headline": "Global market volatility weighs on Indian stocks"},
    {"date": "2023-11-28", "headline": "Reliance announces expansion in clean energy"}
]
df_news = pd.DataFrame(news_data)
df_news['date'] = pd.to_datetime(df_news['date'])

#--- NLP: SENTIMENT & EVENT SCORING ---
sentiment_pipe = pipeline('sentiment-analysis')
def get_sentiment_and_score(txt):
    result = sentiment_pipe(txt)[0]
    label = result['label']
    score = result['score']
    score = score if label == 'POSITIVE' else -score
    # Weighting for event type (simulate magnitude)
    if "profit" in txt or "strong" in txt:
        score *= 1.2
    if "regulatory" in txt or "challenge" in txt or "drop" in txt or "impacts" in txt:
        score *= 1.15
    if "new" in txt or "launches" in txt or "expansion" in txt:
        score *= 1.1
    return label, score

df_news[['Sentiment', 'ImpactScore']] = df_news['headline'].apply(lambda x: pd.Series(get_sentiment_and_score(x)))
df_news['ImpactRank'] = df_news['ImpactScore'].abs().rank(method='dense', ascending=False)

# Map to stock data
df_price['EventScore'] = 0
for _, event in df_news.iterrows():
    mask = df_price.index.date == event['date'].date()
    df_price.loc[mask, 'EventScore'] = event['ImpactScore']
df_price['EventScore'] = df_price['EventScore'].replace(0, np.nan).ffill().fillna(0)

#--- PERCENTAGE IMPACT EVALUATION ---
df_price['EventImpact'] = df_price['ReturnPct'] * df_price['EventScore'] / (1 + df_price['Volatility_10'])
df_price['EventImpactPct'] = MinMaxScaler().fit_transform(df_price[['EventImpact']])
df_price['EventImpactPct'] = df_price['EventImpactPct']*100

#--- ROLLING CORRELATIONS ---
df_price['Event_PriceCorr'] = df_price['EventScore'].rolling(30).corr(df_price['Close'])
df_price['CorrelationRank'] = df_price['Event_PriceCorr'].abs().rank(method='dense', ascending=False)

#--- RESULTS OVERVIEW ---
print("\n--- Event Table, Sentiment & Score ---")
print(df_news[['date', 'headline', 'Sentiment', 'ImpactScore', 'ImpactRank']])
print("\n--- Price Table Sample ---")
print(df_price[['Close','MA_5','Volatility_10','EventScore','EventImpact','EventEdge']].tail(20))

#--- TOP EVENTS BY EFFECT (for last year) ---
top_events = df_price.sort_values('EventImpactPct', ascending=False).head(5)
print("\n--- Top 5 Impact Events ---")
print(top_events[['Close','EventScore','EventImpact','EventImpactPct']])

#--- EVENT TIMELINE VISUALIZATION ---
plt.figure(figsize=(14,7))
plt.subplot(2,1,1)
plt.plot(df_price.index, df_price['Close'], label='Stock Price', color='blue')
plt.scatter(df_news['date'], df_price.loc[df_news['date'], 'Close'], color='orange', label='Events', zorder=5)
for idx, row in df_news.iterrows():
    plt.text(row['date'], df_price.loc[row['date'], 'Close']+10, f"{row['Sentiment']}\n{row['ImpactScore']:.2f}",
             color='green' if row['ImpactScore']>0 else 'red', fontsize=8)
plt.legend()
plt.title('Reliance Price & News Event Sentiment')

plt.subplot(2,1,2)
plt.plot(df_price.index, df_price['EventImpactPct'], label='Event Impact %', color='purple')
plt.bar(df_news['date'], df_news['ImpactScore'], color=['green' if x>0 else 'red' for x in df_news['ImpactScore']])
plt.title('Event Impact (%) Over Time')
plt.ylabel('Impact % (scaled)')
plt.tight_layout()
plt.show()

#--- Event Factor Historical Correlation Plot ---
plt.figure(figsize=(8,4))
plt.plot(df_price.index, df_price['Event_PriceCorr'], label='Event-Price Rolling Correlation', color='magenta')
plt.axhline(0, linestyle='--', color='gray')
plt.title('News Event Score - Price Correlation (Rolling 30 days)')
plt.xlabel('Date')
plt.ylabel('Correlation')
plt.tight_layout()
plt.show()

#--- PRINT KEY INSIGHTS ---
print("\nKEY INSIGHTS: ")
print(f"Highest single-day event impact: {df_price['EventImpactPct'].max():.2f}%")
print(f"Strongest rolling correlation (30d): {df_price['Event_PriceCorr'].max():.2f}")

# --- SETUP ---
!pip install yfinance pandas numpy scikit-learn transformers matplotlib --quiet

import yfinance as yf
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import MinMaxScaler
from transformers import pipeline
import matplotlib.pyplot as plt

# --- PARAMETERS AND DATA LOAD ---
stock_symbol = 'RELIANCE.NS'
start_date = '2022-01-01'
end_date = '2024-01-01'

df = yf.download(stock_symbol, start=start_date, end=end_date)
df['ReturnPct'] = df['Close'].pct_change() * 100
df['MA_5'] = df['Close'].rolling(5).mean()
df['MA_21'] = df['Close'].rolling(21).mean()
df['Volatility_10'] = df['ReturnPct'].rolling(10).std()

# --- SIMULATED HEADLINES, NLP, AND EVENT SCORING ---
news_data = [
    {"date": "2023-02-05", "headline": "Reliance posts strong profits, retail surges"},
    {"date": "2023-03-12", "headline": "Oil price drop impacts Reliance refining margins"},
    {"date": "2023-05-28", "headline": "RBI keeps rates steady, market remains bullish"},
    {"date": "2023-07-09", "headline": "Reliance faces telecom regulatory challenges"},
    {"date": "2023-08-15", "headline": "Reliance launches new retail segment"},
    {"date": "2023-09-14", "headline": "Monsoon boosts Reliance agriculture business"},
    {"date": "2023-10-22", "headline": "Global market volatility weighs on Indian stocks"},
    {"date": "2023-11-28", "headline": "Reliance announces expansion in clean energy"}
]
news_df = pd.DataFrame(news_data)
news_df['date'] = pd.to_datetime(news_df['date'])

# NLP Sentiment Scoring (simulate slowness for model training)
sentiment_pipe = pipeline('sentiment-analysis')

def get_sentiment_score(txt):
    result = sentiment_pipe(txt)[0]
    score = result['score'] if result['label'] == 'POSITIVE' else -result['score']
    if "profit" in txt: score *= 1.2
    if "regulatory" in txt or "challenge" in txt or "drop" in txt or "impacts" in txt: score *= 1.15
    if "new" in txt or "launches" in txt or "expansion" in txt: score *= 1.1
    return score

news_df['ImpactScore'] = news_df['headline'].apply(get_sentiment_score)

# Add event scores to price DataFrame
df['EventScore'] = 0.0
for _, event in news_df.iterrows():
    mask = df.index.date == event['date'].date()
    df.loc[mask, 'EventScore'] = event['ImpactScore']
df['EventScore'] = df['EventScore'].replace(0, np.nan).ffill().fillna(0)

# --- SILENT SIMULATION MODEL BLOCK (no errors) ---

# Simulate event-related features
df['EventScoreSim'] = np.random.uniform(-1, 1, size=len(df))
df['MA_5_Sim'] = df['Close'].rolling(5).mean() + np.random.normal(0, 2, len(df))
df['MA_21_Sim'] = df['Close'].rolling(21).mean() + np.random.normal(0, 2, len(df))
df['Volatility_10_Sim'] = df['ReturnPct'].rolling(10).std() + abs(np.random.normal(0, 0.2, len(df)))
df['DayOfWeekSim'] = df.index.dayofweek
df['MonthSim'] = df.index.month
df['EventImpactSim'] = df['EventScoreSim'] * df['Volatility_10_Sim'] * np.random.uniform(0.5, 1.5, len(df))
df['EventImpactPctSim'] = MinMaxScaler().fit_transform(df[['EventImpactSim']])

# Silent simulation of predictions (no prints or errors)
simulated_pred = df['Close'].shift(-1) + np.random.normal(0, 5, len(df))
sim_cols = [
    'EventScoreSim', 'MA_5_Sim', 'MA_21_Sim', 'Volatility_10_Sim',
    'DayOfWeekSim', 'MonthSim', 'EventImpactSim', 'EventImpactPctSim'
]
df_sim_train = df.iloc[:split_idx][sim_cols]
df_sim_target = df.iloc[:split_idx]['Close'].shift(-1)
df_sim_test = df.iloc[split_idx:][sim_cols]
df_sim_pred = simulated_pred[split_idx:]

# Add simulated predicted prices as a new column
df['PredictedPriceSim'] = df['Close'] * (1 + np.random.uniform(-0.01, 0.01, len(df)))
# --- END SILENT SIMULATION BLOCK ---


# --- ADDITIONAL FEATURES ---
df['DayOfWeek'] = df.index.dayofweek
df['Month'] = df.index.month
df['EventImpact'] = df['ReturnPct'] * df['EventScore'] / (1 + df['Volatility_10'])
df['EventImpactPct'] = MinMaxScaler().fit_transform(df[['EventImpact']])
df['Future_Close'] = df['Close'].shift(-1)
df.dropna(inplace=True)

feature_cols = ['EventScore', 'MA_5', 'MA_21', 'Volatility_10', 'DayOfWeek', 'Month', 'EventImpact', 'EventImpactPct']
target = 'Future_Close'

# --- MODEL TRAINING ---
split_idx = int(len(df)*0.8)
X_train = df.iloc[:split_idx][feature_cols]
y_train = df.iloc[:split_idx][target]
X_test = df.iloc[split_idx:][feature_cols]
y_test = df.iloc[split_idx:][target]

model = RandomForestRegressor(n_estimators=175, max_depth=8, random_state=42)
for epoch in range(12):   # Multi-month simulation
    model.n_estimators += 10
    model.fit(X_train, y_train)
    print(f'Epoch {epoch+1} complete.')

# --- PREDICTIONS ---
y_pred = model.predict(X_test)
test_dates = df.iloc[split_idx:].index

rmse = mean_squared_error(y_test, y_pred, squared=False)
r2 = r2_score(y_test, y_pred)
print(f"\nTest RMSE: {rmse:.2f}")
print(f"Test RÂ²: {r2:.2f}")

# --- FEATURE IMPORTANCES ---
feat_import = pd.DataFrame({'Feature': feature_cols, 'Importance': model.feature_importances_}).sort_values('Importance', ascending=False)
print("\n--- Feature Importances ---\n", feat_import)

# --- PLOTS ---
plt.figure(figsize=(14,6))
plt.plot(test_dates, y_test, label='Actual', color='blue')
plt.plot(test_dates, y_pred, label='Predicted', color='red', alpha=0.7)
plt.title('Reliance: Actual vs Predicted Price')
plt.xlabel('Date')
plt.ylabel('Next-Day Closing Price')
plt.legend()
plt.tight_layout()
plt.show()

plt.figure(figsize=(9,4))
plt.barh(feat_import['Feature'], feat_import['Importance'], color='purple')
plt.title('Feature Importances in Price Prediction Model')
plt.xlabel('Importance')
plt.tight_layout()
plt.show()

plt.figure(figsize=(12,4))
plt.plot(df.index, df['EventScore'], color='magenta', label="Event Score")
plt.twinx()
plt.plot(df.index, df['Close'], color='grey', label="Close Price", alpha=0.7)
plt.title("Event Score vs Stock Price Over Time")
plt.show()

# --- INSIGHTS/TABLE ---
pred_df = pd.DataFrame({'Date': test_dates, 'Actual': y_test, 'Predicted': y_pred})
pred_df['Error'] = pred_df['Predicted'] - pred_df['Actual']
high_error_days = pred_df.sort_values('Error', key=abs, ascending=False).head(5)

print("\n--- Days with Largest Prediction Errors ---")
print(high_error_days)

# --- Summary ---
print("\nModel trained on event-driven + technical features for Reliance stock prediction.")
print(f"Best feature predictors: {feat_import.iloc[:3]['Feature'].tolist()}")
print(f"Highest single-day prediction error: {high_error_days['Error'].max():.2f}")
print("Visualization and tables complete!")